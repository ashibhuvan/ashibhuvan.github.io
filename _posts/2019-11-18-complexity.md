---
layout: post
title: Time Complexity of Data Structures and Algorithims
---




![_config.yml]({{ site.baseurl }}/images/bigo.png)


![_config.yml]({{ site.baseurl }}/images/timecomplexity.png)
Why is HashMap time complexity so low for search, insertion, and deletion? Because HashMap or table is unique values of hash. If you want to know the memory location of say a row that is stored with key "hello", just use the hash equation on hello and that value should be unique and maybe another equation to determine the memory location. 


Sorting Algorithims - quick overview

QuickSort: you have a list of n elements in random order. Pick an element to be the pivot point (in simplest terms pick the last element to be the pivot point. Iterate through the array putting all the values < the pivot point before the pivot and vice versa for the values greater than. You now have 2 sub arrays. Repeat the process that has just been done for those sub arrays. You will get time complexity in best scenario at nLOGn.

![_config.yml]({{ site.baseurl }}/images/algocomplexity.png)

